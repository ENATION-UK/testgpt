"""
LLMæœåŠ¡æ¨¡å—
"""

import json
import os
import re
import pandas as pd
from typing import List, Dict, Any

from browser_use.llm.deepseek.chat import ChatDeepSeek
from browser_use.llm.messages import SystemMessage, UserMessage, ContentPartTextParam

from ..config_manager import ConfigManager
from .excel_utils import convert_excel_to_test_cases

class LLMService:
    """LLMæœåŠ¡ç±»"""
    
    @staticmethod
    def _load_model_config() -> dict:
        """åŠ è½½æ¨¡å‹é…ç½®"""
        try:
            config_manager = ConfigManager()
            config_path = config_manager.get_model_config_path()
            if config_path.exists():
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
            else:
                # é»˜è®¤é…ç½®
                config = {
                    "model_type": "deepseek",
                    "api_key": os.getenv("DEEPSEEK_API_KEY", ""),
                    "base_url": "https://api.deepseek.com/v1",
                    "model": "deepseek-chat",
                    "temperature": 0.7,
                    "max_tokens": None
                }
            return config
        except Exception as e:
            print(f"åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤é…ç½®
            return {
                "model_type": "deepseek",
                "api_key": os.getenv("DEEPSEEK_API_KEY", ""),
                "base_url": "https://api.deepseek.com/v1",
                "model": "deepseek-chat",
                "temperature": 0.7,
                "max_tokens": None
            }

    @staticmethod
    async def analyze_excel_with_llm(df: pd.DataFrame, import_options: dict) -> List[dict]:
        """ä½¿ç”¨å¤§æ¨¡å‹åˆ†æExcelå†…å®¹å¹¶è½¬æ¢ä¸ºæµ‹è¯•ç”¨ä¾‹æ ¼å¼"""
        try:
            # åŠ è½½æ¨¡å‹é…ç½®
            config = LLMService._load_model_config()
            
            # æ£€æŸ¥é…ç½®æœ‰æ•ˆæ€§
            if not config.get("api_key"):
                print("è­¦å‘Š: æ¨¡å‹é…ç½®ä¸­ç¼ºå°‘APIå¯†é’¥ï¼Œä½¿ç”¨å¤‡ç”¨è½¬æ¢é€»è¾‘")
                return convert_excel_to_test_cases(df, import_options)

            # å°†DataFrameè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            excel_content = df.to_string(index=False)
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""
è¯·åˆ†æä»¥ä¸‹Excelè¡¨æ ¼å†…å®¹ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæµ‹è¯•ç”¨ä¾‹æ ¼å¼ã€‚

Excelå†…å®¹ï¼š
{excel_content}

å¯¼å…¥é€‰é¡¹ï¼š
- é»˜è®¤çŠ¶æ€: {import_options.get('defaultStatus', 'active')}
- é»˜è®¤ä¼˜å…ˆçº§: {import_options.get('defaultPriority', 'medium')}
- é»˜è®¤åˆ†ç±»: {import_options.get('defaultCategory', 'å¯¼å…¥')}

è¯·å°†Excelä¸­çš„æ¯ä¸€è¡Œè½¬æ¢ä¸ºä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
    "name": "æµ‹è¯•ç”¨ä¾‹åç§°",
    "description": "æµ‹è¯•ç”¨ä¾‹æè¿°",
    "task_content": "å…·ä½“çš„æµ‹è¯•ä»»åŠ¡å†…å®¹",
    "status": "active/inactive/draft",
    "priority": "low/medium/high/critical",
    "category": "åˆ†ç±»åç§°",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
    "expected_result": "æœŸæœ›ç»“æœ"
}}

è¯·è¿”å›JSONæ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼Œæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹åŒ…å«ä¸Šè¿°æ‰€æœ‰å­—æ®µã€‚
å¦‚æœExcelä¸­æ²¡æœ‰æŸäº›å­—æ®µï¼Œè¯·ä½¿ç”¨å¯¼å…¥é€‰é¡¹ä¸­çš„é»˜è®¤å€¼ã€‚
"""
            print("å³å°†å‘é€ç»™å¤§æ¨¡å‹çš„æç¤ºè¯å¦‚ä¸‹ï¼š")
            print(prompt)

            # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºç›¸åº”çš„èŠå¤©å®ä¾‹
            if config.get("model_type") == "deepseek":
                # åˆ›å»ºDeepSeekèŠå¤©å®ä¾‹
                chat_config = {
                    'base_url': config.get('base_url', 'https://api.deepseek.com/v1'),
                    'model': config.get('model', 'deepseek-chat'),
                    'api_key': config.get('api_key'),
                }
                
                # æ·»åŠ å¯é€‰å‚æ•°
                if config.get('temperature') is not None:
                    chat_config['temperature'] = config.get('temperature')
                if config.get('max_tokens') is not None:
                    chat_config['max_tokens'] = config.get('max_tokens')
                
                deepseek_chat = ChatDeepSeek(**chat_config)
                
                messages = [
                    SystemMessage(content=[ContentPartTextParam(text="ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹åˆ†æä¸“å®¶")]),
                    UserMessage(content=prompt)
                ]
                
                print("ğŸš€ è°ƒç”¨å¤§æ¨¡å‹...")
                response = await deepseek_chat.ainvoke(messages)
                llm_response = response.completion
                
            else:
                raise Exception(f"æš‚ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {config.get('model_type')}")
            
            # è§£æå“åº”
            try:
                # å°è¯•ä»å“åº”ä¸­æå–JSON
                json_match = re.search(r'\[.*\]', llm_response, re.DOTALL)
                if json_match:
                    test_cases = json.loads(json_match.group())
                else:
                    # å¦‚æœæ— æ³•è§£æJSONï¼Œä½¿ç”¨ç®€å•çš„è½¬æ¢é€»è¾‘
                    test_cases = convert_excel_to_test_cases(df, import_options)
            except Exception as e:
                print(f"JSONè§£æå¤±è´¥: {e}")
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„è½¬æ¢é€»è¾‘
                test_cases = convert_excel_to_test_cases(df, import_options)
            
            return test_cases
            
        except Exception as e:
            print(f"å¤§æ¨¡å‹åˆ†æå¤±è´¥: {e}")
            # å¦‚æœå¤§æ¨¡å‹åˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„è½¬æ¢é€»è¾‘
            return convert_excel_to_test_cases(df, import_options) 